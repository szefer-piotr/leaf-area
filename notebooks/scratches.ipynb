{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequential(num_layers, \n",
    "                      nodes_per_layer, \n",
    "                      activation=nn.ReLU, \n",
    "                      final_activation = None):\n",
    "    \"\"\"\n",
    "    Create a Sequential module with the specified number of layers and nodes.\n",
    "\n",
    "    Args:\n",
    "        num_layers (int): Number of layers in the Sequential module.\n",
    "        nodes_per_layer (list[int]): List of integers specifying the number of nodes in each layer.\n",
    "                                     Must have `num_layers + 1` elements (input size + output sizes).\n",
    "        activation (nn.Module): The activation function to use between layers. Default is nn.ReLU.\n",
    "        final_activation (nn.Module): Optional final activation function after the last layer.\n",
    "\n",
    "    Returns:\n",
    "        nn.Sequential: The constructed Sequential module.\n",
    "    \"\"\"\n",
    "    if len(nodes_per_layer) != num_layers + 1:\n",
    "        raise ValueError('Number of nodes per layer must have the same length as the number of layers + 1!')\n",
    "    layers = []\n",
    "    for i in range(num_layers):\n",
    "        layers.append(nn.Linear(nodes_per_layer[i], nodes_per_layer[i+1]))\n",
    "        if i < num_layers-1:\n",
    "            layers.append(activation())\n",
    "    if final_activation is not None:\n",
    "        layers.append(final_activation())\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "def replace_final_layer(\n",
    "        model, \n",
    "        num_layers=4, \n",
    "        nodes_per_layer=[128,64,32,1],\n",
    "        activation='nn.ReLU',\n",
    "        final_activation='None',\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Replace the final layer of a PyTorch model with a new layer.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): A PyTorch model instance.\n",
    "        new_layer (nn.Module): The new layer to replace the final layer with.\n",
    "    \n",
    "    Returns:\n",
    "        nn.Module: The model with the final layer replaced.\n",
    "    \"\"\"\n",
    "    \n",
    "    activation = eval(activation)\n",
    "    final_activation = eval(final_activation)\n",
    "    # print(f\"[DEBUG] Activation {activation} and final activation {final_activation}\")\n",
    "    children = list(model.named_children())\n",
    "    # print(f\"[DEBUG] Children: {len(children)} of class {type(children)}\")\n",
    "    last_name, last_module = children[-1]\n",
    "    new_layer_in = last_module.in_features\n",
    "    \n",
    "    # last_module_out = last_module._out\n",
    "    new_layer = create_sequential(\n",
    "        num_layers, \n",
    "        [new_layer_in] + nodes_per_layer,\n",
    "        activation,\n",
    "        final_activation)\n",
    "    # print(f\"[DEBUG] Last module {last_module} and new_layer {new_layer}\")\n",
    "    setattr(model, last_name, new_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = replace_final_layer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer_configs = {\n",
    "    'loss_fn': 'torch.nn.MSELoss',\n",
    "    'optimizer': {\n",
    "        'optimizer': 'torch.optim.Adam',\n",
    "        'amsgrad': 'True'},\n",
    "    'scheduler': {'scheduler': 'torch.optim.lr_scheduler.StepLR',\n",
    "                  'step_size': 7,\n",
    "                  'gamma': 0.1},\n",
    "    'metric': 'torcheval.metrics.R2Score'  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer_configs = {\n",
    "    'loss_fn': 'torch.nn.MSELoss',\n",
    "    'loss_fn_params': None,\n",
    "    'optimizer': 'torch.optim.Adam',\n",
    "    'optimizer_params': {\n",
    "        'amsgrad': 'True'\n",
    "        },\n",
    "    'scheduler': 'torch.optim.lr_scheduler.StepLR',\n",
    "    'scheduler_params':{\n",
    "        'step_size': 7,\n",
    "        'gamma': 0.1\n",
    "    },\n",
    "    'metric': 'torcheval.metrics.R2Score',\n",
    "    'metric_params': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_fn': 'torch.nn.MSELoss',\n",
       " 'loss_fn_params': None,\n",
       " 'optimizer': 'torch.optim.Adam',\n",
       " 'optimizer_params': {'amsgrad': 'True'},\n",
       " 'scheduler': 'torch.optim.lr_scheduler.StepLR',\n",
       " 'scheduler_params': {'step_size': 7, 'gamma': 0.1},\n",
       " 'metric': 'torcheval.metrics.R2Score',\n",
       " 'metric_params': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initializer_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "def string_to_callable(callable_string):\n",
    "    \"\"\"\n",
    "    Convert a string to a callable. This function helps to convert Kedro's\n",
    "    parameters into callables that can be passed to model building functions\n",
    "    in pipeline.\n",
    "    \"\"\"\n",
    "    if callable_string == 'None':\n",
    "        return None\n",
    "    module_name, function_name = callable_string.rsplit('.', 1)\n",
    "\n",
    "    print(f'[INFO] Module called {module_name} with a function name: {function_name}')\n",
    "\n",
    "    module = importlib.import_module(module_name)\n",
    "    func = getattr(module, function_name)\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_class_with_params(\n",
    "        class_name='torch.optim.lr_scheduler.StepLR', \n",
    "        parameters={'step_size': 7, 'gamma': 0.1}):\n",
    "    return string_to_callable(class_name)(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Module called torch.optim.lr_scheduler with a function name: StepLR\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "StepLR.__init__() missing 1 required positional argument: 'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minstantiate_class_with_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36minstantiate_class_with_params\u001b[0;34m(class_name, parameters)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minstantiate_class_with_params\u001b[39m(\n\u001b[1;32m      2\u001b[0m         class_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.optim.lr_scheduler.StepLR\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m7\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.1\u001b[39m}):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstring_to_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: StepLR.__init__() missing 1 required positional argument: 'optimizer'"
     ]
    }
   ],
   "source": [
    "instantiate_class_with_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'a': 1, 'b': 2}\n",
    "my_dict['ananas'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'ananas': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('a', 1), ('b', 2), ('ananas', 1)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf-area-MmBPJx5b-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
